{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check that we have correct TensorFlow version installed\n",
    "tf_version = tf.__version__\n",
    "print(\"TensorFlow version: {}\".format(tf_version))\n",
    "assert \"1.4\" <= tf_version, \"TensorFlow r1.4 or later is needed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Wks/GitHub/MeTaNoV/PubNativeTest\\data\\training_cleaned_2.csv\n",
      "C:/Wks/GitHub/MeTaNoV/PubNativeTest\\data\\validation_cleaned_2.csv\n"
     ]
    }
   ],
   "source": [
    "PATH = os.environ['PWD']\n",
    "\n",
    "PATH_DATA = PATH + os.sep + \"data\"\n",
    "FILE_TRAIN = PATH_DATA + os.sep + \"training_cleaned_2.csv\"\n",
    "print(FILE_TRAIN)\n",
    "FILE_TEST = PATH_DATA + os.sep + \"validation_cleaned_2.csv\"\n",
    "print(FILE_TEST)\n",
    "\n",
    "PATH_GRAPH = PATH + os.sep + \"graphs\"\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "TRAIN_EPOCHS = 500\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's list the feature that we will use in accordance to our cleaned datasets\n",
    "# feature_names = ['v1','v2','v3','v4','v6','v7','v8','v9','v10','v11','v12','v14','v15']\n",
    "# csv_defaults = [['b'],[0.],[0.],['u'],['c'],['v'],[0.],['t'],['t'],[0],['t'],[0],[0],['yes.']]\n",
    "feature_names = ['v1','v2','v3','v7','v8','v9','v10','v11','v12','v15']\n",
    "csv_defaults = [['b'],[0.],[0.],['v'],[0.],['t'],['t'],[0],['t'],[0],['yes.']]\n",
    "\n",
    "# Our classifiers are using an input_fn to get batch input in their respective training/evaluation/prediction phase\n",
    "def pn_input_fn(file_path, perform_shuffle=False, repeat_count=1):\n",
    "    def decode_csv(line):\n",
    "        \"\"\"Convert a CSV row to a dictonary of features and a label\"\"\"\n",
    "        parsed_line = tf.decode_csv(line, csv_defaults)\n",
    "        label = parsed_line[-1]  # Last element is the label\n",
    "        del parsed_line[-1]  # Delete last element\n",
    "        features = parsed_line\n",
    "        return dict(zip(feature_names, features)), label\n",
    "\n",
    "    dataset = (tf.data.TextLineDataset(file_path)\n",
    "               .skip(1)  # Skip header row\n",
    "               .map(decode_csv))\n",
    "    if perform_shuffle is True:\n",
    "        dataset = dataset.shuffle(buffer_size=512)\n",
    "    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    \n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now create our features columns as described in the data analysis\n",
    "# Since a DNN only accept Dense columns, we will wrap our Categorical or Bucketized columns into indicator columns\n",
    "# If we had buckets with big sizes, we would have used embeddings columns instead\n",
    "feature_columns = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=\"v1\", \n",
    "            vocabulary_list=[\"a\", \"b\"])\n",
    "    ),\n",
    "    tf.feature_column.numeric_column('v2'),\n",
    "    tf.feature_column.numeric_column('v3'),\n",
    "#     tf.feature_column.indicator_column(\n",
    "#         tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key=\"v4\", \n",
    "#             vocabulary_list=[\"u\", \"y\", \"l\"])\n",
    "#     ),\n",
    "#     tf.feature_column.indicator_column(\n",
    "#         tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key=\"v6\", \n",
    "#             vocabulary_list=[\"c\", \"q\", \"W\", \"cc\", \"x\", \"aa\", \"i\", \"m\", \"k\", \"e\", \"ff\", \"d\", \"j\", \"r\"])\n",
    "#     ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=\"v7\", \n",
    "            vocabulary_list=[\"v\", \"h\", \"bb\", \"ff\", \"z\", \"j\", \"n\", \"dd\", \"o\"])\n",
    "    ),\n",
    "    tf.feature_column.numeric_column('v8'),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=\"v9\", \n",
    "            vocabulary_list=[\"f\", \"t\"])\n",
    "    ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=\"v10\", \n",
    "            vocabulary_list=[\"f\", \"t\"])\n",
    "    ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.bucketized_column(\n",
    "            tf.feature_column.numeric_column('v11'),\n",
    "            list(np.linspace(1.,20.,20)))\n",
    "    ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=\"v12\", \n",
    "            vocabulary_list=[\"f\", \"t\"])\n",
    "    ),\n",
    "#     tf.feature_column.indicator_column(\n",
    "#         tf.feature_column.bucketized_column(\n",
    "#             tf.feature_column.numeric_column('v14'),\n",
    "#             list(np.linspace(50.,500.,10)))\n",
    "#     ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.bucketized_column(\n",
    "            tf.feature_column.numeric_column('v15'),\n",
    "            list(np.linspace(500.,5000.,10)))\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:/Wks/GitHub/MeTaNoV/PubNativeTest\\\\graphs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001670C892828>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:/Wks/GitHub/MeTaNoV/PubNativeTest\\graphs\\model.ckpt.\n",
      "INFO:tensorflow:loss = 70.77728, step = 1\n",
      "INFO:tensorflow:global_step/sec: 76.896\n",
      "INFO:tensorflow:loss = 0.40806323, step = 101 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2828\n",
      "INFO:tensorflow:loss = 1.2597532, step = 201 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.953\n",
      "INFO:tensorflow:loss = 2.6759322, step = 301 (1.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2069\n",
      "INFO:tensorflow:loss = 4.880002, step = 401 (1.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.8419\n",
      "INFO:tensorflow:loss = 4.4804096, step = 501 (1.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.4812\n",
      "INFO:tensorflow:loss = 16.850733, step = 601 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8801\n",
      "INFO:tensorflow:loss = 0.5163624, step = 701 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.5452\n",
      "INFO:tensorflow:loss = 0.58633566, step = 801 (1.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.3729\n",
      "INFO:tensorflow:loss = 0.66780853, step = 901 (1.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7829\n",
      "INFO:tensorflow:loss = 4.8245964, step = 1001 (1.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.3916\n",
      "INFO:tensorflow:loss = 5.30852, step = 1101 (1.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.5926\n",
      "INFO:tensorflow:loss = 7.765765, step = 1201 (1.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0168\n",
      "INFO:tensorflow:loss = 0.3310507, step = 1301 (1.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7822\n",
      "INFO:tensorflow:loss = 0.18767785, step = 1401 (1.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9554\n",
      "INFO:tensorflow:loss = 0.60012186, step = 1501 (1.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.779\n",
      "INFO:tensorflow:loss = 0.49364436, step = 1601 (1.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.376\n",
      "INFO:tensorflow:loss = 4.324989, step = 1701 (1.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.101\n",
      "INFO:tensorflow:loss = 0.6748593, step = 1801 (1.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9388\n",
      "INFO:tensorflow:loss = 0.13981345, step = 1901 (1.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.7132\n",
      "INFO:tensorflow:loss = 0.12180862, step = 2001 (1.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.6708\n",
      "INFO:tensorflow:loss = 0.289565, step = 2101 (1.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8368\n",
      "INFO:tensorflow:loss = 0.12555575, step = 2201 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.4959\n",
      "INFO:tensorflow:loss = 0.34924647, step = 2301 (1.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9531\n",
      "INFO:tensorflow:loss = 3.5179513, step = 2401 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.4693\n",
      "INFO:tensorflow:loss = 2.9036417, step = 2501 (1.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.462\n",
      "INFO:tensorflow:loss = 0.005381859, step = 2601 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.953\n",
      "INFO:tensorflow:loss = 0.24658933, step = 2701 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6298\n",
      "INFO:tensorflow:loss = 0.5668868, step = 2801 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3997\n",
      "INFO:tensorflow:loss = 0.36842805, step = 2901 (1.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.186\n",
      "INFO:tensorflow:loss = 1.2212421, step = 3001 (1.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.9317\n",
      "INFO:tensorflow:loss = 1.4237587, step = 3101 (1.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3132\n",
      "INFO:tensorflow:loss = 0.16812575, step = 3201 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0118\n",
      "INFO:tensorflow:loss = 0.024726082, step = 3301 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.0417\n",
      "INFO:tensorflow:loss = 0.015642973, step = 3401 (1.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0747\n",
      "INFO:tensorflow:loss = 0.47436905, step = 3501 (1.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.134\n",
      "INFO:tensorflow:loss = 1.7543566, step = 3601 (1.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.6198\n",
      "INFO:tensorflow:loss = 0.26186082, step = 3701 (1.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.4317\n",
      "INFO:tensorflow:loss = 0.096640036, step = 3801 (1.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2184\n",
      "INFO:tensorflow:loss = 0.023832748, step = 3901 (1.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2073\n",
      "INFO:tensorflow:loss = 0.07668631, step = 4001 (1.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0286\n",
      "INFO:tensorflow:loss = 0.21004406, step = 4101 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.6746\n",
      "INFO:tensorflow:loss = 0.016920615, step = 4201 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0927\n",
      "INFO:tensorflow:loss = 0.77965444, step = 4301 (1.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1117\n",
      "INFO:tensorflow:loss = 0.09792759, step = 4401 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0847\n",
      "INFO:tensorflow:loss = 0.035752326, step = 4501 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3132\n",
      "INFO:tensorflow:loss = 0.02215448, step = 4601 (1.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0913\n",
      "INFO:tensorflow:loss = 0.07991992, step = 4701 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1339\n",
      "INFO:tensorflow:loss = 0.2776839, step = 4801 (1.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.3012\n",
      "INFO:tensorflow:loss = 0.62304187, step = 4901 (1.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.3658\n",
      "INFO:tensorflow:loss = 0.009018013, step = 5001 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3662\n",
      "INFO:tensorflow:loss = 0.045265414, step = 5101 (1.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.3429\n",
      "INFO:tensorflow:loss = 0.033850648, step = 5201 (1.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0426\n",
      "INFO:tensorflow:loss = 0.043720208, step = 5301 (1.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.7807\n",
      "INFO:tensorflow:loss = 0.14349198, step = 5401 (1.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9793\n",
      "INFO:tensorflow:loss = 0.44587147, step = 5501 (1.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8835\n",
      "INFO:tensorflow:loss = 0.08007302, step = 5601 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8102\n",
      "INFO:tensorflow:loss = 0.076414764, step = 5701 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0006\n",
      "INFO:tensorflow:loss = 0.029193427, step = 5801 (1.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8356\n",
      "INFO:tensorflow:loss = 0.0415069, step = 5901 (1.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1532\n",
      "INFO:tensorflow:loss = 0.29957736, step = 6001 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.7359\n",
      "INFO:tensorflow:loss = 1.3958403, step = 6101 (1.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2873\n",
      "INFO:tensorflow:loss = 2.0109427, step = 6201 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8102\n",
      "INFO:tensorflow:loss = 0.02659706, step = 6301 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.4073\n",
      "INFO:tensorflow:loss = 0.06670658, step = 6401 (1.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9045\n",
      "INFO:tensorflow:loss = 0.0048672105, step = 6501 (1.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2505\n",
      "INFO:tensorflow:loss = 0.13300401, step = 6601 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7872\n",
      "INFO:tensorflow:loss = 0.08105353, step = 6701 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1533\n",
      "INFO:tensorflow:loss = 0.09362058, step = 6801 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.5486\n",
      "INFO:tensorflow:loss = 0.021531891, step = 6901 (1.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9793\n",
      "INFO:tensorflow:loss = 0.055702582, step = 7001 (1.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7669\n",
      "INFO:tensorflow:loss = 0.014695027, step = 7101 (1.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.6155\n",
      "INFO:tensorflow:loss = 0.18912609, step = 7201 (1.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5606\n",
      "INFO:tensorflow:loss = 0.018117467, step = 7301 (1.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.3492\n",
      "INFO:tensorflow:loss = 0.4936169, step = 7401 (1.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04247649, step = 7501 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8163\n",
      "INFO:tensorflow:loss = 0.08897162, step = 7601 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8102\n",
      "INFO:tensorflow:loss = 0.014997469, step = 7701 (1.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2349\n",
      "INFO:tensorflow:loss = 0.06940451, step = 7801 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2167\n",
      "INFO:tensorflow:loss = 0.1349801, step = 7901 (1.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7492\n",
      "INFO:tensorflow:loss = 0.1704191, step = 8001 (1.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3897\n",
      "INFO:tensorflow:loss = 0.08201565, step = 8101 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3897\n",
      "INFO:tensorflow:loss = 0.046640746, step = 8201 (1.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5606\n",
      "INFO:tensorflow:loss = 0.027927004, step = 8301 (1.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8834\n",
      "INFO:tensorflow:loss = 0.030244626, step = 8401 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9783\n",
      "INFO:tensorflow:loss = 0.0011160646, step = 8501 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.8434\n",
      "INFO:tensorflow:loss = 0.15710469, step = 8601 (1.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.1616\n",
      "INFO:tensorflow:loss = 0.18121733, step = 8701 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6297\n",
      "INFO:tensorflow:loss = 0.017982658, step = 8801 (1.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8218\n",
      "INFO:tensorflow:loss = 0.009121953, step = 8901 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.1638\n",
      "INFO:tensorflow:loss = 0.010305201, step = 9001 (1.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0501\n",
      "INFO:tensorflow:loss = 0.06174154, step = 9101 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.0369\n",
      "INFO:tensorflow:loss = 0.08074458, step = 9201 (1.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3774\n",
      "INFO:tensorflow:loss = 0.16342677, step = 9301 (1.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3715\n",
      "INFO:tensorflow:loss = 0.0014462805, step = 9401 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1756\n",
      "INFO:tensorflow:loss = 0.018987121, step = 9501 (1.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3897\n",
      "INFO:tensorflow:loss = 0.00515525, step = 9601 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2829\n",
      "INFO:tensorflow:loss = 0.03364055, step = 9701 (1.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.691\n",
      "INFO:tensorflow:loss = 0.027798187, step = 9801 (1.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.6547\n",
      "INFO:tensorflow:loss = 3.2057993, step = 9901 (1.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8565\n",
      "INFO:tensorflow:loss = 0.0068213176, step = 10001 (1.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9173\n",
      "INFO:tensorflow:loss = 0.00851265, step = 10101 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.9346\n",
      "INFO:tensorflow:loss = 0.008190064, step = 10201 (1.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7653\n",
      "INFO:tensorflow:loss = 0.0035523616, step = 10301 (1.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0518\n",
      "INFO:tensorflow:loss = 0.053905852, step = 10401 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0288\n",
      "INFO:tensorflow:loss = 0.21125023, step = 10501 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.6479\n",
      "INFO:tensorflow:loss = 0.019472115, step = 10601 (1.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.1156\n",
      "INFO:tensorflow:loss = 0.008761268, step = 10701 (1.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6832\n",
      "INFO:tensorflow:loss = 0.011136655, step = 10801 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.5833\n",
      "INFO:tensorflow:loss = 0.043912973, step = 10901 (1.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.6923\n",
      "INFO:tensorflow:loss = 0.043728765, step = 11001 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.5957\n",
      "INFO:tensorflow:loss = 0.11085517, step = 11101 (1.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.5502\n",
      "INFO:tensorflow:loss = 0.014757447, step = 11201 (1.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.8772\n",
      "INFO:tensorflow:loss = 0.0019911982, step = 11301 (1.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8959\n",
      "INFO:tensorflow:loss = 0.0026106033, step = 11401 (1.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.9584\n",
      "INFO:tensorflow:loss = 0.012200219, step = 11501 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3132\n",
      "INFO:tensorflow:loss = 0.0074716453, step = 11601 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0928\n",
      "INFO:tensorflow:loss = 0.024739496, step = 11701 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.6688\n",
      "INFO:tensorflow:loss = 0.11941269, step = 11801 (1.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.111\n",
      "INFO:tensorflow:loss = 0.004104346, step = 11901 (1.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5603\n",
      "INFO:tensorflow:loss = 0.025042664, step = 12001 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2531\n",
      "INFO:tensorflow:loss = 0.008543819, step = 12101 (1.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8045\n",
      "INFO:tensorflow:loss = 0.013456525, step = 12201 (1.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.5617\n",
      "INFO:tensorflow:loss = 0.0022847175, step = 12301 (1.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.3667\n",
      "INFO:tensorflow:loss = 0.01650562, step = 12401 (1.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8402\n",
      "INFO:tensorflow:loss = 0.047590278, step = 12501 (1.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2534\n",
      "INFO:tensorflow:loss = 0.024207236, step = 12601 (1.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.6215\n",
      "INFO:tensorflow:loss = 0.0030174714, step = 12701 (1.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1105\n",
      "INFO:tensorflow:loss = 0.0024856178, step = 12801 (1.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.1371\n",
      "INFO:tensorflow:loss = 0.025553562, step = 12901 (1.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0118\n",
      "INFO:tensorflow:loss = 0.01767978, step = 13001 (1.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.1328\n",
      "INFO:tensorflow:loss = 0.0077893585, step = 13101 (1.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.7678\n",
      "INFO:tensorflow:loss = 0.019381128, step = 13201 (1.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3662\n",
      "INFO:tensorflow:loss = 0.024303252, step = 13301 (1.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.905\n",
      "INFO:tensorflow:loss = 0.031096712, step = 13401 (1.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.5397\n",
      "INFO:tensorflow:loss = 0.0033220616, step = 13501 (1.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3661\n",
      "INFO:tensorflow:loss = 0.012801637, step = 13601 (1.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.3175\n",
      "INFO:tensorflow:loss = 0.07373679, step = 13701 (1.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3077\n",
      "INFO:tensorflow:loss = 0.0227739, step = 13801 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9396\n",
      "INFO:tensorflow:loss = 0.019329652, step = 13901 (1.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0444\n",
      "INFO:tensorflow:loss = 0.004786644, step = 14001 (1.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.5833\n",
      "INFO:tensorflow:loss = 0.04430618, step = 14101 (1.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0169\n",
      "INFO:tensorflow:loss = 0.010875774, step = 14201 (1.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7184\n",
      "INFO:tensorflow:loss = 0.033801693, step = 14301 (1.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2233\n",
      "INFO:tensorflow:loss = 0.0064793956, step = 14401 (1.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2526\n",
      "INFO:tensorflow:loss = 0.0045368825, step = 14501 (1.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.0148\n",
      "INFO:tensorflow:loss = 0.00074096647, step = 14601 (1.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.6134\n",
      "INFO:tensorflow:loss = 0.026790762, step = 14701 (1.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7233\n",
      "INFO:tensorflow:loss = 0.017865356, step = 14801 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.289\n",
      "INFO:tensorflow:loss = 0.022757925, step = 14901 (1.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.953\n",
      "INFO:tensorflow:loss = 0.00025935774, step = 15001 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.5328\n",
      "INFO:tensorflow:loss = 0.0038386532, step = 15101 (1.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.6546\n",
      "INFO:tensorflow:loss = 0.039844107, step = 15201 (1.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.6597\n",
      "INFO:tensorflow:loss = 0.0031604588, step = 15301 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8356\n",
      "INFO:tensorflow:loss = 0.036270186, step = 15401 (1.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.2888\n",
      "INFO:tensorflow:loss = 0.018290835, step = 15501 (1.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0016612812, step = 15601 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.0434\n",
      "INFO:tensorflow:loss = 0.0010581437, step = 15701 (1.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2829\n",
      "INFO:tensorflow:loss = 0.0015893449, step = 15801 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8835\n",
      "INFO:tensorflow:loss = 0.00689167, step = 15901 (1.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8101\n",
      "INFO:tensorflow:loss = 0.050842423, step = 16001 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0846\n",
      "INFO:tensorflow:loss = 0.017099693, step = 16101 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8357\n",
      "INFO:tensorflow:loss = 0.0014028571, step = 16201 (1.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.966\n",
      "INFO:tensorflow:loss = 0.018045746, step = 16301 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.9524\n",
      "INFO:tensorflow:loss = 0.035977542, step = 16401 (1.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3158\n",
      "INFO:tensorflow:loss = 0.00093148724, step = 16501 (1.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.664\n",
      "INFO:tensorflow:loss = 0.00067705446, step = 16601 (1.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7668\n",
      "INFO:tensorflow:loss = 0.024608698, step = 16701 (1.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5994\n",
      "INFO:tensorflow:loss = 0.03258702, step = 16801 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3774\n",
      "INFO:tensorflow:loss = 0.004047296, step = 16901 (1.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.1506\n",
      "INFO:tensorflow:loss = 0.0009176221, step = 17001 (1.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8163\n",
      "INFO:tensorflow:loss = 0.0030966066, step = 17101 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.0181\n",
      "INFO:tensorflow:loss = 0.041461993, step = 17201 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.6821\n",
      "INFO:tensorflow:loss = 0.052043945, step = 17301 (1.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.668\n",
      "INFO:tensorflow:loss = 0.0032346575, step = 17401 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7685\n",
      "INFO:tensorflow:loss = 0.002603914, step = 17501 (1.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7563\n",
      "INFO:tensorflow:loss = 0.0019237953, step = 17601 (1.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17610 into C:/Wks/GitHub/MeTaNoV/PubNativeTest\\graphs\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.028519865.\n",
      "INFO:tensorflow:Training done!\n"
     ]
    }
   ],
   "source": [
    "# Now we can define our classifier(s) and perform the associated training and evaluation\n",
    "# Note: by default, it performs a binary classification, which fits our need, we will just give the label vocabulary\n",
    "# since we didn't transform our label column previously\n",
    "\n",
    "# For the linear classifier, we obtain an accuracy in training of 95% and an evaluation accuracy of 67%\n",
    "# It is not a surprise that the linear classifier is not able to train properly and evaluate even more poorly,\n",
    "# but we had to quickly assert it.\n",
    "# classifier = tf.estimator.LinearClassifier(\n",
    "#     feature_columns=feature_columns,\n",
    "#     label_vocabulary=[\"yes.\", \"no.\"],\n",
    "#     model_dir=PATH_GRAPH)\n",
    "\n",
    "# To be able to capture the non-linearity of the given dataset, let's then focus on a DNN architecture\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[512, 256, 128],\n",
    "#     dropout=0.5,\n",
    "#     optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "#       learning_rate=0.1,\n",
    "#       l1_regularization_strength=0.001\n",
    "#     ),\n",
    "    label_vocabulary=[\"yes.\", \"no.\"],\n",
    "    model_dir=PATH_GRAPH)\n",
    "\n",
    "training_results = classifier.train(\n",
    "    input_fn=lambda: pn_input_fn(FILE_TRAIN, True, TRAIN_EPOCHS)\n",
    ")\n",
    "tf.logging.info(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-05-10:44:23\n",
      "INFO:tensorflow:Restoring parameters from C:/Wks/GitHub/MeTaNoV/PubNativeTest\\graphs\\model.ckpt-17610\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-05-10:44:24\n",
      "INFO:tensorflow:Saving dict for global step 17610: accuracy = 0.99971604, accuracy_baseline = 0.9267462, auc = 1.0, auc_precision_recall = 1.0, average_loss = 0.0005681569, global_step = 17610, label/mean = 0.07325383, loss = 0.055584684, prediction/mean = 0.0730703\n",
      "INFO:tensorflow:Training results:\n",
      "INFO:tensorflow:   accuracy, was: 0.99971604347229\n",
      "INFO:tensorflow:   accuracy_baseline, was: 0.9267461895942688\n",
      "INFO:tensorflow:   auc, was: 1.0\n",
      "INFO:tensorflow:   auc_precision_recall, was: 1.0\n",
      "INFO:tensorflow:   average_loss, was: 0.0005681568873114884\n",
      "INFO:tensorflow:   label/mean, was: 0.07325383275747299\n",
      "INFO:tensorflow:   loss, was: 0.055584684014320374\n",
      "INFO:tensorflow:   prediction/mean, was: 0.07307030260562897\n",
      "INFO:tensorflow:   global_step, was: 17610\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-05-10:44:27\n",
      "INFO:tensorflow:Restoring parameters from C:/Wks/GitHub/MeTaNoV/PubNativeTest\\graphs\\model.ckpt-17610\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-05-10:44:28\n",
      "INFO:tensorflow:Saving dict for global step 17610: accuracy = 0.8429319, accuracy_baseline = 0.5183246, auc = 0.87154144, auc_precision_recall = 0.90578455, average_loss = 3.810904, global_step = 17610, label/mean = 0.5183246, loss = 363.94135, prediction/mean = 0.47738615\n",
      "INFO:tensorflow:Evaluation results:\n",
      "INFO:tensorflow:   accuracy, was: 0.8429319262504578\n",
      "INFO:tensorflow:   accuracy_baseline, was: 0.518324613571167\n",
      "INFO:tensorflow:   auc, was: 0.871541440486908\n",
      "INFO:tensorflow:   auc_precision_recall, was: 0.905784547328949\n",
      "INFO:tensorflow:   average_loss, was: 3.810904026031494\n",
      "INFO:tensorflow:   label/mean, was: 0.518324613571167\n",
      "INFO:tensorflow:   loss, was: 363.94134521484375\n",
      "INFO:tensorflow:   prediction/mean, was: 0.47738614678382874\n",
      "INFO:tensorflow:   global_step, was: 17610\n"
     ]
    }
   ],
   "source": [
    "training_results = classifier.evaluate(\n",
    "    input_fn=lambda: pn_input_fn(FILE_TRAIN, False, 1)\n",
    ")\n",
    "tf.logging.info(\"Training results:\")\n",
    "for key in training_results:\n",
    "    tf.logging.info(\"   {}, was: {}\".format(key, training_results[key]))\n",
    "\n",
    "# Using a DNN Classifier, we were able to train our model properly\n",
    "# Let's now confirm that our model is valid with the evaluation phase on our validation dataset\n",
    "evaluate_results = classifier.evaluate(\n",
    "    input_fn=lambda: pn_input_fn(FILE_TEST, False, 1)\n",
    ")\n",
    "tf.logging.info(\"Evaluation results:\")\n",
    "for key in evaluate_results:\n",
    "    tf.logging.info(\"   {}, was: {}\".format(key, evaluate_results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion1*: After several fine tuning, we managed to have an accuracy of 82% and an AUC precision/recall of 0.88 which is encouraging since as we mentioned in the data analysis, the model learned with an unbalanced data set and still managed to perform rather well on the validation set. We will do a deeper analysis of the data in `Deeper_Data_Exploration.ipynd`\n",
    "\n",
    "*Conclusion2*: The second analysis led us to ignore some more features, namely `v4`, `v6` and `v14` which enabled us to reach an accuracy of nearly 85% and an AUC precision/recall of 0.91\n",
    "\n",
    "Worth to Note:\n",
    "=> v10 = (v11 != 0)\n",
    "=> \n",
    "\n",
    "*Final Conclusion*: A better understanding of the data, knowing to what correspond the given features would certainly help, i.e. we could perhaps derive some better feature out of it. Moreover, as we mentioned in the first data analysis, the training and validation dataset are not balanced equally, and therefore, the model is not able to correct this bias probably introduced in the training phase. Also, having more data would certainly help further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
